{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c2e5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified by Sam Pollard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3a745-cc95-41ea-94c4-9558cdfa1332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b04dd49-25e0-4637-9d65-70787fa309a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frames = 10\n",
    "EGOSCHEMA_FOLDER = \"<EGOSCHEMA-PATH>\"\n",
    "VID_FOLDER = f\"{EGOSCHEMA_FOLDER}/videos\"\n",
    "\n",
    "if not os.path.exists(f\"egoschema_features_{frames}\"):\n",
    "    print(\"making folder\")\n",
    "    os.mkdir(f\"egoschema_features_{frames}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6acfaa-19b5-4569-9dfa-f44391dc2dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "VID_PATH = VID_FOLDER\n",
    "\n",
    "to_add = []\n",
    "for q_uid in os.listdir(f\"{VID_PATH}\"):\n",
    "    if not os.path.exists(f\"{VID_PATH}/{q_uid[:q_uid.rfind('.')]}.npy\"):\n",
    "        to_add.append(q_uid[:q_uid.rfind('.')])\n",
    "        total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee7127a-1d9e-4cba-80e1-ebd766d82c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "for q_uid in os.listdir(f\"./egoschema_features_{frames}/\"):\n",
    "    if torch.from_numpy(np.load(f\"./egoschema_features_{frames}/{q_uid}\").astype(\"float32\")).shape[0] != frames:\n",
    "        to_add.append(q_uid[:q_uid.rfind('.')])\n",
    "        print(q_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cd2456-72c5-40c8-a4c9-aa995b5e3970",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = []\n",
    "columns = [\"video_path\", \"feature_path\"]\n",
    "\n",
    "\n",
    "for q_uid_mp4 in os.listdir(f\"{VID_PATH}\"):\n",
    "    q_uid = q_uid_mp4[:q_uid_mp4.rfind(\".\")]\n",
    "    if \"ipynb\" in q_uid_mp4:\n",
    "        continue\n",
    "        \n",
    "    if q_uid not in to_add:\n",
    "        continue\n",
    "    row = [f\"{VID_PATH}/\"+ q_uid_mp4, f\"./egoschema_features_{frames}/\" + q_uid]\n",
    "    table.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b654e56-cb5e-49ab-984c-816d8cf1a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(table,columns=columns)\n",
    "df.to_csv(\"test_additional_paths.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9638396-1d35-477b-b4fe-bd8100ca5a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import math\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from extract.video_loader import VideoLoader\n",
    "from torch.utils.data import DataLoader\n",
    "from extract.preprocessing import Preprocessing\n",
    "from extract.random_sequence_shuffler import RandomSequenceSampler\n",
    "from args import MODEL_DIR\n",
    "import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c368205-bdd7-4c4a-b614-4ed1ae67a976",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = VideoLoader(\n",
    "    \"test_additional_paths.csv\",\n",
    "    framerate = frames / 180,  # one feature per second max\n",
    "    size=224,\n",
    "    centercrop=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750aa3af-c7d9-4b56-955b-5c1a26762e16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_dataset = len(dataset)\n",
    "sampler = RandomSequenceSampler(n_dataset, frames)\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=10,\n",
    "    sampler=sampler if n_dataset > 10 else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8045bfe4-736b-4005-844e-059c19ef3494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocess = Preprocessing()\n",
    "model, _ = clip.load(\"ViT-L/14\", download_root=MODEL_DIR)\n",
    "model.eval()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fafea1-9bff-4484-9adf-205373583f76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with th.no_grad():\n",
    "    for k, data in enumerate(loader):\n",
    "        input_file = data[\"input\"][0]\n",
    "        output_file = data[\"output\"][0]\n",
    "        if len(data[\"video\"].shape) > 3:\n",
    "            print(\n",
    "                \"Computing features of video {}/{}: {}\".format(\n",
    "                    k + 1, n_dataset, input_file\n",
    "                )\n",
    "            )\n",
    "            video = data[\"video\"].squeeze()\n",
    "            if len(video.shape) == 4:\n",
    "                video = preprocess(video)\n",
    "                n_chunk = len(video)\n",
    "                features = th.cuda.FloatTensor(n_chunk, 768).fill_(0)\n",
    "                n_iter = int(math.ceil(n_chunk / float(128)))\n",
    "                for i in tqdm(range(n_iter)):\n",
    "                    min_ind = i * 128\n",
    "                    max_ind = (i + 1) * 128\n",
    "                    video_batch = video[min_ind:max_ind].cuda()\n",
    "                    batch_features = model.encode_image(video_batch)\n",
    "                    if 0:\n",
    "                        batch_features = F.normalize(batch_features, dim=1)\n",
    "                    features[min_ind:max_ind] = batch_features\n",
    "                features = features.cpu().numpy()\n",
    "                if 1:\n",
    "                    features = features.astype(\"float16\")\n",
    "                np.save(output_file, features)\n",
    "        else:\n",
    "            print(\"Video {} already processed.\".format(input_file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "frozenbilm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
