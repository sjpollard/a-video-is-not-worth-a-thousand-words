## Image-Text Data
* [**LLaVA-OneVision**](https://llava-vl.github.io/blog/2024-08-05-llava-onevision/), [**Cambrian-1**](https://github.com/cambrian-mllm/cambrian), [**Pixmo**](https://github.com/allenai/molmo), [**Docmatix**](https://huggingface.co/datasets/HuggingFaceM4/Docmatix)
* [**Coyo-700M**](https://github.com/kakaobrain/coyo-dataset), [**LAION-5B**](https://laion.ai/blog/laion-5b/), [**Object365**](https://www.objects365.org/overview.html), [**SA-1B**](https://ai.meta.com/datasets/segment-anything/), [**DenseFusion-1M**](https://github.com/baaivision/DenseFusion), [**ShareGPT4o**](https://sharegpt4o.github.io/), [**ShareGPT4V**](https://sharegpt4v.github.io/), [**TextCaps**](https://textvqa.org/textcaps/)
* [**BLIP3-OCR**](https://huggingface.co/datasets/Salesforce/blip3-ocr-200m), [**COCO-Text**](https://bgshih.github.io/cocotext/), [**TextOCR**](https://textvqa.org/textocr/)
* [**Pixel Parsing**](https://huggingface.co/pixparse), [**UReader**](https://github.com/LukeForeverYoung/UReader), [**SynthDoG**](https://github.com/clovaai/donut), [**FUNSD**](https://guillaumejaume.github.io/FUNSD/), [**DUDE**](https://github.com/duchallenge-team/dude), [**Vary**](https://github.com/Ucas-HaoranWei/Vary), [**pdfa-eng-wds**](https://huggingface.co/datasets/pixparse/pdfa-eng-wds), [**idl-wds**](https://huggingface.co/datasets/pixparse/idl-wds)
* [**Chart-to-Text**](https://github.com/vis-nlp/Chart-to-text), [**MMC-Instruction**](https://huggingface.co/datasets/xywang1/MMC), [**MultiUI**](https://huggingface.co/datasets/neulab/MultiUI)
* [**Osprey-724K**](https://github.com/CircleRadon/Osprey), [**MDVP-Data**](https://github.com/AFeng-x/Draw-and-Understand), [**ADE-20K**](https://ade20k.csail.mit.edu/), [**Flickr-30K**](https://shannon.cs.illinois.edu/DenotationGraph/), [**GranD**](https://grounding-anything.com/)

## Video-Text Data
* [**LLaVA-Video**](https://llava-vl.github.io/blog/2024-09-30-llava-video/), [**ShareGPT4o-Video**](https://github.com/ShareGPT4Omni/ShareGPT4Video), [**FineVideo**](https://github.com/huggingface/fineVideo), [**CinePile**](https://ruchitrawal.github.io/cinepile/), [**ShareGemini**](https://github.com/Share14/ShareGemini), [**VideoGPT+**](https://github.com/mbzuai-oryx/VideoGPT-plus), [**VideoRefer**](https://github.com/DAMO-NLP-SG/VideoRefer), [**ActivityNet**](http://activity-net.org/index.html), [**YouCook2**](http://youcook2.eecs.umich.edu/), [**Ego4D**](https://ego4d-data.org/), [**ViTT**](https://github.com/google-research-datasets/Video-Timeline-Tags-ViTT), [**QuerYD**](https://www.robots.ox.ac.uk/~vgg/data/queryd/), [**HiREST**](https://hirest-cvpr2023.github.io/), [**Charades-STA**](https://opendatalab.com/OpenDataLab/Charades-STA), [**Moment-10M**](https://github.com/DCDmllm/Momentor), [**COIN**](https://coin-dataset.github.io/)
## Text Data
* [**Magpie**](https://github.com/magpie-align/magpie), [**Synthia**](https://huggingface.co/migtissera), [**Infinity-Instruct**](https://huggingface.co/datasets/BAAI/Infinity-Instruct), [**Numinamath**](https://huggingface.co/collections/AI-MO/numinamath-6697df380293bcfdbc1d978c), [**Evol-Instruct-143K**](https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V/blob/ed7ce9b4f1a882aaa48fa7ffe3d8365d2251b581/Evol-Instruct-GPT4-Turbo-143K.json), [**Tulu 3**](https://huggingface.co/collections/allenai/tulu-3-datasets-673b8df14442393f7213f372)
